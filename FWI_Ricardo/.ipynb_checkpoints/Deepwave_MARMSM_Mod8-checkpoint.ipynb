{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GUNOgiEYK7VS"
   },
   "source": [
    "# Deepwave FWI  Test_Adam_Marm_151_401_shuffling_lr=4\n",
    "\n",
    "### Adapted by Ricardo de Bragan√ßa in Nov 06th, 2020\n",
    "from:\n",
    "Janaki Vamaraju LSRTM codes and \n",
    "Deepwave FWI Example by Alan Richardson (Ausar Geophysical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the below parameters to output.txt file\n",
    "%logstart -o -r -t -q output.txt rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General info\n",
    "# using Adam Optimization\n",
    "# Shuffling sources every epoch\n",
    "# SCHUSTER's MARMOUSI MODEL\n",
    "\n",
    "# General parameters\n",
    "GPU=1      # which GPU to use\n",
    "plot=False # Plot Intermediate results\n",
    "sigma=30   # Initial model smoothness  \n",
    "\n",
    "# Inversion parameters\n",
    "num_batches = 32\n",
    "num_epochs = 5000\n",
    "\n",
    "#gamma = 300  # Does not apply, Adam uses lr (learning rate) instead of gamma\n",
    "# Adam learning rate\n",
    "lr = 4\n",
    "\n",
    "# Modeling parameters\n",
    "freq = 14\n",
    "dx = 10\n",
    "dt = 0.001\n",
    "nt = 4001\n",
    "num_shots = 32\n",
    "num_receivers_per_shot = 200\n",
    "\n",
    "# receiver_spacing = # computed below from ny,dx and num_receivers_per_shot\n",
    "\n",
    "# Close the ouput.txt file with saved parameters\n",
    "%logstop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rt4YffFf1zJl"
   },
   "outputs": [],
   "source": [
    "# Need to restart runtime before this step\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import deepwave\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vmin= 1500.0 vmax= 3550.000244140625 vmed= 2525.0001220703125 vwidth= 1025.0001220703125\n"
     ]
    }
   ],
   "source": [
    "#plot=True\n",
    "# Load the true model\n",
    "filename='Marm151_401.mat'\n",
    "mat=scipy.io.loadmat(filename)['vel']\n",
    "#mat = np.loadtxt('marmhard2.dat')\n",
    "#mat = np.pad(mat,((10,0),(0,0)),'edge') #RB add some water layer\n",
    "#RB Get model size\n",
    "ny = np.size(mat,1);\n",
    "nz = np.size(mat,0);\n",
    "#RB compute true model mean value and width for future model normalization\n",
    "max=np.max(mat)\n",
    "min=np.min(mat)\n",
    "med=(max+min)/2.\n",
    "wid=(max-min)/2.\n",
    "\n",
    "print('vmin=',min,'vmax=',max,'vmed=',med,'vwidth=',wid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot==True:\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.imshow(mat,vmin=min,vmax=max, aspect=1)\n",
    "    plt.title('True model')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RB Open file to write results\n",
    "f = open('marmsm_Mod8_log.txt','a+')\n",
    "writer = csv.writer(f)\n",
    "\n",
    "#RB Write header\n",
    "fields=['Epoch','it','loss.item','epoch_loss','it_lap','epoch_lap']\n",
    "writer.writerow(fields)\n",
    "f.flush()\n",
    "os.fsync(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/adhara/miniconda3/envs/deepwave/lib/python3.7/site-packages/torch/cuda/__init__.py:106: UserWarning: \n",
      "NVIDIA RTX A5000 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.\n",
      "If you want to use the NVIDIA RTX A5000 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    }
   ],
   "source": [
    "# Specify which GPU to use (in multi GPU machines)\n",
    "torch.cuda.set_device(GPU)  #RB Necessary if device <> 0\n",
    "GPU_string='cuda:'+str(GPU)\n",
    "device = torch.device(GPU_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YMvR-Hqv11e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ny= 401 nz= 151 nt= 4001 dx= 10 freq= 14\n",
      "shots= 32 recs/shot= 200 ds= 125.3125 dr= 20.05\n"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "##freq = 14\n",
    "##dx = 10\n",
    "##dt = 0.001\n",
    "\n",
    "#RB nt = int(2 / dt) # 2s\n",
    "#nt = int(0.9 * int(np.sqrt((nz*dx)**2 + (ny*dx)**2) / 2000 / dt))\n",
    "#nt =       3 * int(np.sqrt((nz*dx)**2 + (ny*dx)**2) / 2000 / dt)\n",
    "##nt = 4001\n",
    "\n",
    "num_dims = 2\n",
    "#num_shots = 32\n",
    "num_sources_per_shot = 1\n",
    "#num_receivers_per_shot = 200\n",
    "\n",
    "#RB source_spacing = 25.0\n",
    "#RB receiver_spacing = 10.0\n",
    "source_spacing = ny * dx / num_shots\n",
    "receiver_spacing = ny * dx / num_receivers_per_shot\n",
    "#receiver_spacing = 8.\n",
    "\n",
    "print('ny=',ny,'nz=',nz,'nt=',nt,'dx=',dx,'freq=',freq)\n",
    "print('shots=',num_shots,'recs/shot=',num_receivers_per_shot, \\\n",
    "      'ds=',source_spacing,'dr=',receiver_spacing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aE40Gcx413Sj"
   },
   "outputs": [],
   "source": [
    "# Create arrays containing the source and receiver locations\n",
    "# x_s: Source locations [num_shots, num_sources_per_shot, num_dimensions]\n",
    "# x_r: Receiver locations [num_shots, num_receivers_per_shot, num_dimensions]\n",
    "x_s = torch.zeros(num_shots, num_sources_per_shot, num_dims)\n",
    "x_s[:, 0, 1] = torch.arange(num_shots).float() * source_spacing\n",
    "#x_s[:, 0, 0] = 100. #RB Set source depth\n",
    "\n",
    "x_r = torch.zeros(num_shots, num_receivers_per_shot, num_dims)\n",
    "x_r[0, :, 1] = torch.arange(num_receivers_per_shot).float() * receiver_spacing\n",
    "x_r[:, :, 1] = x_r[0, :, 1].repeat(num_shots, 1)\n",
    "\n",
    "#RB Shuffle shot coordinates\n",
    "###idx = torch.randperm(num_shots)\n",
    "###x_s = x_s.view(-1,2)[idx].view(x_s.size())\n",
    "\n",
    "#RB Set Receiver depth\n",
    "#x_r[0, :, 0] = 100.\n",
    "#x_r[:, :, 0] = x_r[0, :, 0].repeat(num_shots, 1)\n",
    "\n",
    "# Create true source amplitudes [nt, num_shots, num_sources_per_shot]\n",
    "# I use Deepwave's Ricker wavelet function. The result is a normal Tensor - you\n",
    "# can use whatever Tensor you want as the source amplitude.\n",
    "source_amplitudes_true = (deepwave.wavelets.ricker(freq, nt, dt, 1/freq)\n",
    "                          .reshape(-1, 1, 1)\n",
    "                          .repeat(1, num_shots, num_sources_per_shot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f52f0278ac8>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(source_amplitudes_true[:180,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N2dbGVKx16J2"
   },
   "outputs": [],
   "source": [
    "#RB Generate a cte velocy model (with water velocity)\n",
    "mat2 = np.ones((nz,ny),np.float32)*1500.\n",
    "mat2[nz-1,int(ny/2)]=max  # put a pixel with true upper velocity to fix a propagator problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot==True:\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.imshow(mat2,vmin=min,vmax=max, aspect=1)\n",
    "    plt.title('Uniform')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RB Convert models to PyTorch Tensors\n",
    "model_true = torch.Tensor(mat) # Convert to a PyTorch Tensor\n",
    "model_cte = torch.Tensor(mat2) # Convert to a PyTorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zfjDVs6Q17k2"
   },
   "outputs": [],
   "source": [
    "###### Create 'true' data \n",
    "prop = deepwave.scalar.Propagator({'vp': model_true.to(device)}, dx)\n",
    "receiver_amplitudes_all = prop(source_amplitudes_true.to(device),\n",
    "                                x_s.to(device),\n",
    "                                x_r.to(device), dt).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot==True:\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.imshow(receiver_amplitudes_all[:,2].cpu().detach().numpy(),vmin=-.05,vmax=.05, aspect='auto')\n",
    "    plt.title('Model seismogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create direct arrivals data\n",
    "prop2 = deepwave.scalar.Propagator({'vp': model_cte.to(device)}, dx)\n",
    "receiver_amplitudes_cte = prop2(source_amplitudes_true.to(device),\n",
    "                                x_s.to(device),\n",
    "                                x_r.to(device), dt).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot==True:\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.imshow(receiver_amplitudes_cte[:,2].cpu().detach().numpy(),vmin=-.05,vmax=.05, aspect='auto')\n",
    "    plt.title('Direct wave seismogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude direct waves from true data (they don't bring info from subsurface)\n",
    "receiver_amplitudes_true = receiver_amplitudes_all - receiver_amplitudes_cte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot==True:\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.imshow(receiver_amplitudes_true[:,2].cpu().detach().numpy(),vmin=-.05,vmax=.05, aspect='auto')\n",
    "    plt.title('Model seismogram w direct waves removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WriJROlj2fUb",
    "outputId": "558d572d-d34f-4635-d606-2fd2a1476a8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4001, 32, 200])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that the returned receiver amplitudes have shape\n",
    "# [nt, num_shots, num_receivers_per_shot]\n",
    "receiver_amplitudes_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RB Create a smoothed model\n",
    "\n",
    "#RB start with true model\n",
    "mat3 = np.copy(mat)\n",
    "#RB Filter image heavly\n",
    "mat3 = scipy.ndimage.gaussian_filter(mat3,sigma=sigma) #10,50  #5%,10%\n",
    "if plot==True:\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.imshow(mat3,vmin=min,vmax=max)\n",
    "    plt.title('mat3 smoothed from true model')\n",
    "    plt.colorbar()\n",
    "    \n",
    "#RB Force water table to be 1500 m/s (avoid imperfect direct wav removal)    \n",
    "mat3[0:26,:]=1500.\n",
    "\n",
    "#RB Plot model\n",
    "if plot==True:\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.imshow(mat3,vmin=min,vmax=max)\n",
    "    plt.title('mat3 fixed water table')\n",
    "    plt.colorbar()\n",
    "\n",
    "#RB We may want to smooth the water table transition\n",
    "#RB but I think it's a bad idea (not tested)\n",
    "# mat3 = scipy.ndimage.gaussian_filter(mat3,sigma=4)\n",
    "\n",
    "#RB Optionally we may import a initial model from file\n",
    "#filename='Marm151_401_smooth.mat'\n",
    "#mat3=scipy.io.loadmat(filename)['vel0']\n",
    "\n",
    "#RB Ensure that the initial model has the same range of the true model by\n",
    "#RB forcing one of its slowest pixel to have the true's model lower velocity and\n",
    "#RB forcing one of its fastest pixel to have the true's model upper velocity\n",
    "#RB find max & min values of mat3\n",
    "smin=np.min(mat3)\n",
    "smax=np.max(mat3)\n",
    "indmin = np.where(mat3==smin)\n",
    "indmax = np.where(mat3==smax)\n",
    "# Take first pixel with minimum velocity and force it to true's model minimum velocity\n",
    "mat3[indmin[0][0],indmin[1][0]]=min\n",
    "# Take first pixel with maximum velocity and force it to true's model maximum velocity\n",
    "mat3[indmax[0][0],indmax[1][0]]=max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RB Plot the initial model\n",
    "if plot==True:\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.imshow(mat3,vmin=min,vmax=max)\n",
    "    plt.title('mat3 after 2nd filter (if applied)')\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3550.000244140625 1500.0\n",
      "should be:\n",
      "3550.000244140625 1500.0\n"
     ]
    }
   ],
   "source": [
    "#RB Check if it have the same max and min velocities of true model\n",
    "smin=np.min(mat3)\n",
    "smax=np.max(mat3)\n",
    "print(smax,smin)\n",
    "print('should be:')\n",
    "print(max,min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RB Save true and initial model to file\n",
    "filename='Marm_Mod8_models.mat'\n",
    "scipy.io.savemat(filename, mdict={'True':mat, 'Init':mat3}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RB Normalize initial model to (-1,1) range\n",
    "#model_init = (mat3-med)/wid\n",
    "#RB_No_normalization\n",
    "model_init = mat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if plot==True:\n",
    "    #plt.figure(figsize=(12, 3))\n",
    "    #plt.imshow(model_init,vmin=-1,vmax=1)\n",
    "    #plt.title('model_init in (-1,+1) range for inversion')\n",
    "    #plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Pytorch tensor\n",
    "#model_init = torch.from_numpy(np.float32(model_init))\n",
    "model_init = torch.Tensor(model_init)\n",
    "\n",
    "# Make a copy so at the end we can see how far we came from the initial model\n",
    "model = model_init.clone()\n",
    "model = model.to(device)\n",
    "model.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ShSHUhuw5Ns2"
   },
   "outputs": [],
   "source": [
    "#RB AS I am not inverting for source, I could just do\n",
    "#RB source_amplitudes = source_amplitudes_true.clone().to(device)\n",
    "#RB instead of all code below\n",
    "\n",
    "# Create initial guess source amplitude for inversion\n",
    "# I will assume that the true source amplitude is the same for every shot\n",
    "# so I will just create one source amplitude, and PyTorch will backpropagate\n",
    "# updates to it from every shot\n",
    "source_amplitudes_init = (deepwave.wavelets.ricker(freq, nt, dt, 1/freq)\n",
    "                          .reshape(-1, 1, 1))\n",
    "source_amplitudes = source_amplitudes_init.clone()\n",
    "source_amplitudes = source_amplitudes.to(device)\n",
    "#source_amplitudes.requires_grad_(); # Alternative way of requiring gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yhmKrFU28ZPw"
   },
   "outputs": [],
   "source": [
    "# To demonstrate chaining operations, during the inversion I will normalise the\n",
    "# predicted receiver amplitudes so that each trace has a maximum value of 1.\n",
    "# This will be compared (in the cost function) with the true data that has been\n",
    "# similarly scaled. I apply that scaling to the true data now.\n",
    "# This sort of scaling might be useful for real data where the absolute\n",
    "# amplitudes are often not meaningful.\n",
    "rcv_amps_true_max, _ = receiver_amplitudes_true.max(dim=0, keepdim=True)\n",
    "rcv_amps_true_norm = receiver_amplitudes_true / rcv_amps_true_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0M_yOGfd1_cm"
   },
   "outputs": [],
   "source": [
    "# Set-up inversion\n",
    "#gamma = 300\n",
    "criterion = torch.nn.MSELoss()\n",
    "#RB optimizer = torch.optim.SGD([{'params': model }],lr = 100000., momentum=0)\n",
    "optimizer = torch.optim.Adam([{'params': [model], 'lr': lr}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1300
    },
    "colab_type": "code",
    "id": "vAvmIk082BJ8",
    "outputId": "6aaae4ff-1d6d-45a5-9dcd-d4295a26eb66"
   },
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr \n",
    "# The line above captures the output of this cell to the variable cap\n",
    "\n",
    "# Iterative inversion loop\n",
    "t_start = time.time()\n",
    "\n",
    "##num_batches = 32 # split data into batches for speed and reduced memory use\n",
    "num_shots_per_batch = int(num_shots / num_batches)\n",
    "##num_epochs = 1000 # Pass through the entire dataset 30 times\n",
    "\n",
    "#vmin, vmax = np.percentile(model_true.numpy(), [2,98]) # For plotting\n",
    "vmin = min\n",
    "vmax = max\n",
    "#vmin=-1\n",
    "#vmax= 1\n",
    "# Temperature coefficient\n",
    "##Tk =50\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    ep_start=time.time()\n",
    "    print('Processing Epoch:',epoch)\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    #RB Shuffle shot coordinates\n",
    "    idx = torch.randperm(num_shots)\n",
    "    x_s = x_s.view(-1,2)[idx].view(x_s.size())\n",
    "    #RB Shuffle true's seismograms sources with same random values\n",
    "    rcv_amps_true_norm = rcv_amps_true_norm[:,idx,:]\n",
    "    #RB Shuffle direct wave seismograms sources with the same random values\n",
    "    receiver_amplitudes_cte = receiver_amplitudes_cte[:,idx,:]\n",
    "    \n",
    "    for it in range(num_batches):\n",
    "        it_start = time.time()\n",
    "        ###print('    Processing Batch:',it,' of', num_batches)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        #if model.grad is not None:\n",
    "        #    model.grad.data.zero_()\n",
    "        #    print('Preexinting Model Grad zeroed')\n",
    "            \n",
    "        #RB Denormalize model to perform forward propagation\n",
    "        #model2=model*wid+med\n",
    "        #RB or no denormalization if using Adam\n",
    "        model2=model.clone()\n",
    "        #RB Clamp the model within acceptable range\n",
    "        model2=torch.clamp(model,min=min,max=max)        \n",
    "        \n",
    "        #RB Make sure the model have same range of velocities of true's model (fix propag issue)\n",
    "        #RB forcing one of its slowest pixel to have the true's model lower velocity and\n",
    "        #RB forcing one of its fastest pixel to have the true's model upper velocity       \n",
    "        #RB find max & min values of model2\n",
    "        smin=torch.min(model2)\n",
    "        smax=torch.max(model2)\n",
    "        indmin = torch.where(model2==smin)\n",
    "        indmax = torch.where(model2==smax)\n",
    "        # Take first pixel with minimum velocity and force it to true's model minimum velocity\n",
    "        model2[indmin[0][0],indmin[1][0]]=min\n",
    "        # Take first pixel with maximum velocity and force it to true's model maximum velocity\n",
    "        model2[indmax[0][0],indmax[1][0]]=max\n",
    "        \n",
    "        prop3 = deepwave.scalar.Propagator({'vp': model2}, dx)\n",
    "        batch_src_amps = source_amplitudes.repeat(1, num_shots_per_batch, 1)\n",
    "        batch_rcv_amps_true = rcv_amps_true_norm[:,it::num_batches].to(device)\n",
    "        \n",
    "        #RB Alternative normalization (normalizing to dTrue amplitude range)\n",
    "        #batch_rcv_amps_true_max, _ = batch_rcv_amps_true.max(dim=0, keepdim=True)\n",
    "        \n",
    "        #RB get the seismogram of the direct wave for current batch\n",
    "        batch_rcv_amps_cte = receiver_amplitudes_cte[:,it::num_batches].to(device)\n",
    "        \n",
    "        #RB get the current batch source & receiver coordinates\n",
    "        batch_x_s = x_s[it::num_batches].to(device)\n",
    "        batch_x_r = x_r[it::num_batches].to(device)\n",
    "\n",
    "        #print('FWD Propag')\n",
    "        #timer_a = time.time()\n",
    "        \n",
    "        batch_rcv_amps_pred = prop3(batch_src_amps, batch_x_s, batch_x_r, dt)\n",
    "        \n",
    "        #RB Subtract direct wave on all seismograms of current batch\n",
    "        batch_rcv_amps_pred = batch_rcv_amps_pred - batch_rcv_amps_cte\n",
    "        \n",
    "        #RB Normalize\n",
    "        batch_rcv_amps_pred_max, _ = batch_rcv_amps_pred.max(dim=0, keepdim=True)\n",
    "        batch_rcv_amps_pred_norm = batch_rcv_amps_pred / batch_rcv_amps_pred_max\n",
    "        #RB Alternative normalization\n",
    "        #batch_rcv_amps_pred_norm = batch_rcv_amps_pred / batch_rcv_amps_true_max\n",
    "        \n",
    "        #RB ATTENTION: this line will be executed BEFORE GPU finish FWD computation\n",
    "        #RB Measured lab will be much shorter that real\n",
    "        #timer_b = time.time()\n",
    "        #print('Lap=',timer_b-timer_a)\n",
    "        \n",
    "        #print('Loss evaluation')\n",
    "        \n",
    "        #RB Prints for DEBUG purpose\n",
    "        #plt.imshow(batch_rcv_amps_true[:,0,:].cpu().detach().numpy(),vmin=-.05,vmax=.05, aspect='auto')\n",
    "        #plt.colorbar()\n",
    "        #plt.show()\n",
    "        #plt.imshow(batch_rcv_amps_cte[:,0,:].cpu().detach().numpy(),vmin=-.05,vmax=.05, aspect='auto')\n",
    "        #plt.colorbar()\n",
    "        #plt.show()\n",
    "        #plt.imshow(batch_rcv_amps_pred_norm[:,0,:].cpu().detach().numpy(),vmin=-.05,vmax=.05, aspect='auto')\n",
    "        #plt.colorbar()\n",
    "        #plt.show()\n",
    "\n",
    "        #plt.imshow(batch_rcv_amps_true[:,0,:].cpu().detach().numpy(), aspect='auto')\n",
    "        #plt.colorbar()\n",
    "        #plt.show()\n",
    "        #plt.imshow(batch_rcv_amps_cte[:,0,:].cpu().detach().numpy(), aspect='auto')\n",
    "        #plt.colorbar()\n",
    "        #plt.show()\n",
    "        #plt.imshow(batch_rcv_amps_pred_norm[:,0,:].cpu().detach().numpy(), aspect='auto')\n",
    "        #plt.colorbar()\n",
    "        #plt.show()        \n",
    "        \n",
    "        loss = criterion(batch_rcv_amps_pred_norm, batch_rcv_amps_true)            \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        #timer_a = time.time()\n",
    "        #print('Lap=',timer_a-timer_b)\n",
    "        \n",
    "        \n",
    "        #print('Backpropagation')\n",
    "    \n",
    "        loss.backward()\n",
    "        model.grad[0:26,:]=0.\n",
    "        \n",
    "        \n",
    "        #timer_b = time.time()\n",
    "        #print('Lap=',timer_b-timer_a)\n",
    "        \n",
    "        #RB Hill climbing factor computation\n",
    "        #low = 1-2*np.exp(-epoch/Tk)\n",
    "        #alpha = np.random.uniform(low=low,high=1)\n",
    "        #alpha = 1.\n",
    "        \n",
    "        #print('Model update')\n",
    "        #with torch.no_grad():                \n",
    "            #RB update model\n",
    "        #    model =  model - torch.tanh(alpha*gamma*model.grad)                \n",
    "        #model.requires_grad = True        \n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        # Clamp model to acceptable range\n",
    "        #with torch.no_grad():\n",
    "        #    model=torch.clamp(model,min=min,max=max)\n",
    "        #model.requires_grad = True\n",
    "        \n",
    "        it_end = time.time()\n",
    "        #print('Lap=',it_end-timer_b)\n",
    "        \n",
    "        \n",
    "    #RB Write variables to file at each epoch\n",
    "    fields=[epoch,it,loss.item(),epoch_loss, it_end - it_start,it_end - ep_start]\n",
    "    writer.writerow(fields)\n",
    "    f.flush()\n",
    "    os.fsync(f)\n",
    "    \n",
    "    print('Epoch:', epoch, 'Loss: ', epoch_loss)\n",
    "    img = np.array(model.cpu().detach().numpy())\n",
    "\n",
    "    filename='Marmsm_Mod8_epoch_'+str(epoch)+'.mat'\n",
    "    scipy.io.savemat(filename, mdict={'Model': img})\n",
    "       \n",
    "    if epoch % 1 == 0:\n",
    "        \n",
    "        if plot==True:\n",
    "            plt.figure(figsize=(8, 4))\n",
    "            plt.imshow(model.cpu().detach().numpy(), vmin=vmin, vmax=vmax,cmap='viridis')\n",
    "            plt.show() \n",
    "    \n",
    "    epoch+=1\n",
    "\n",
    "t_end = time.time()\n",
    "print('Runtime:', t_end - t_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1133
    },
    "colab_type": "code",
    "id": "lnhtTvyxnBSL",
    "outputId": "ff5a08cb-e8f6-4ea6-a97d-35a1015915aa"
   },
   "outputs": [],
   "source": [
    "# Plot initial, inverted, and true models\n",
    "if plot==True:\n",
    "    figsize = (12, 6)\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(model_init.numpy(), vmin=vmin, vmax=vmax, cmap='viridis')\n",
    "    plt.title('Initial');\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(model.cpu().detach().numpy(), vmin=vmin, vmax=vmax, cmap='viridis')\n",
    "    plt.title('Inverted');\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(model_true.numpy(), vmin=min, vmax=max, cmap='viridis')\n",
    "    plt.title('True');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap2 --no-stderr\n",
    "# The line above captures the output of this cell to the variable cap2\n",
    "\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append cell's captured outputs to file output.txt\n",
    "with open('output.txt', 'a') as f:\n",
    "    f.write(cap.stdout)\n",
    "    f.write(cap2.stdout)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Deepwave_SEAM_example1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
